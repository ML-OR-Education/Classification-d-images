{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Description de MNIST \"Handwritten Digit Recognition Problem\"\n",
    "\n",
    "MNIST est un jeu de données développé par Yann LeCun, Corinna Cortes et Christopher Burges pour évaluer les modèles d’apprentissage automatique sur la classification des chiffres manuscrits.\n",
    "\n",
    "Ce jeu de données a été construit à partir de plusieurs ensembles de documents numérisés provenant du National Institute of Standards and Technology (NIST). Nommé **Modified NIST**, ou **MNIST**.\n",
    "\n",
    "Chaque image est un carré de **28×28 pixels** (soit **784 pixels** au total). Une division standard du jeu de données est utilisée pour l'évaluation et la comparaison des modèles : **60 000 images** servent à l'entraînement du modèle, et un ensemble distinct de **10 000 images** est utilisé pour le tester.\n",
    "\n",
    "Il s'agit d'une tâche de reconnaissance de chiffres. Il y a donc **dix chiffres** (de 0 à 9), soit **dix classes** à prédire. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voici le schéma d’architecture des réseaux de neurones que nous allons réaliser dans ce workshop. \n",
    "\n",
    "<img src=\"TP-CNN-architecture-1.jpg\" width=\"900\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importe les bibliothèques nécessaires pour :\n",
    "\n",
    "* Construire le modèle de réseau de neurones (tensorflow, keras)\n",
    "\n",
    "* Manipuler les données (numpy)\n",
    "\n",
    "* Visualiser des images et des résultats (matplotlib)\n",
    "\n",
    "* Organiser les fichiers si nécessaire (os)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Charger la dataset MNIST\n",
    "\n",
    "La cellule suivante permet de charger le jeu de données MNIST en deux ensembles : x_train, y_train pour l'entraînement, et x_test, y_test pour le test.\n",
    "L’instruction x_train[0].shape permet de vérifier que chaque image est bien de taille 28x28."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "x_train[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Normalisation des images (mise à l'échelle entre 0 et 1)\n",
    "\n",
    "L'objectif est de rendre les valeurs des pixels plus petites (entre 0 et 1) pour faciliter et accélérer l’apprentissage du modèle.\n",
    "\n",
    "Les images de MNIST ont des valeurs entre 0 et 255. En divisant par 255, on obtient des valeurs entre 0 et 1, ce qui améliore la convergence du modèle pendant l’apprentissage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test = x_train / 255.0, x_test / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Construire les modèles\n",
    "\n",
    "Introduction à la section dans laquelle on va définir l’architecture du CNN, c’est-à-dire la séquence de couches qui va transformer l’image d’entrée en une prédiction de chiffre.\n",
    "\n",
    "Comme annoncé en début du workshop nous allons construire trois architectures de réseaux de neurones convolutifs (CNN) de tailles croissantes, pour effectuer une classification sur les images de la dataset MNIST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_small_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(keras.layers.Conv2D(64, (3, 3), input_shape=(28, 28, 1), activation='relu'))\n",
    "    model.add(keras.layers.Conv2D(32, (3, 3), activation='relu'))\n",
    "    model.add(keras.layers.Flatten())\n",
    "    model.add(keras.layers.Dense(10, activation='softmax'))\n",
    "    return model\n",
    "\n",
    "def build_medium_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(keras.layers.Conv2D(32, (5, 5), input_shape=(28, 28, 1), activation='relu'))\n",
    "    model.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(keras.layers.Dropout(0.2))\n",
    "    model.add(keras.layers.Flatten())\n",
    "    model.add(keras.layers.Dense(128, activation='relu'))\n",
    "    model.add(keras.layers.Dense(10, activation='softmax'))\n",
    "    return model\n",
    "\n",
    "def build_large_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(keras.layers.Conv2D(30, (5, 5), input_shape=(28, 28, 1), activation='relu'))\n",
    "    model.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(keras.layers.Conv2D(15, (3, 3), activation='relu'))\n",
    "    model.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(keras.layers.Dropout(0.2))\n",
    "    model.add(keras.layers.Flatten())\n",
    "    model.add(keras.layers.Dense(128, activation='relu'))\n",
    "    model.add(keras.layers.Dense(50, activation='relu'))\n",
    "    model.add(keras.layers.Dense(10, activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Entraîner les modèles\n",
    "\n",
    "Nous allons maintenant comparer les différentes architectures CNN (small, medium, large) :\n",
    "\n",
    "* les entraîner sur MNIST,\n",
    "\n",
    "* enregistrer leur historique d'apprentissage,\n",
    "\n",
    "* sauvegarder les modèles pour une réutilisation ultérieure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Défnir un dictionnaire de modèles CNN\n",
    "models = {\n",
    "    \"small\": build_small_model(), \n",
    "    \"medium\": build_medium_model(), \n",
    "    \"large\": build_large_model()\n",
    "    }\n",
    "\n",
    "#  Définit un dossier où seront enregistrés les résultats.\n",
    "SAVE_DIR = \"mnist_results\"\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "\n",
    "# Initialiser un dictionnaire pour stocker les historiques d’entraînement (perte et précision) de chaque modèle.\n",
    "histories = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.compile(optimizer='SGD', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    history = model.fit(x_train, y_train, epochs=10, validation_data=(x_test, y_test))\n",
    "    histories[name] = history.history\n",
    "    model.save(os.path.join(SAVE_DIR, f\"{name}_model.h5\"))\n",
    "    np.save(os.path.join(SAVE_DIR, f\"{name}_history.npy\"), history.history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<blockquote>\n",
    "Un optimizer est un algorithme qui ajuste les poids du réseau pendant l'entraînement.\n",
    "\n",
    "Exemples connus : 'SGD', 'Adam', 'RMSprop', etc.\n",
    "\n",
    "Vous pouvez essayer différents optimiseurs en les passant au modèle via model.compile(...).\n",
    "\n",
    "Cette exploration permet de tester l'impact de chaque optimizer sur les performances du modèle.\n",
    "</blockquote>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizers = [opt for opt in dir(tf.keras.optimizers) if not opt.startswith(\"__\")]\n",
    "print(optimizers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Plot Accuracy & Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import plot_all_metrics\n",
    "\n",
    "plot_all_metrics(SAVE_DIR, histories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Evaluation\n",
    "\n",
    "On crée un dictionnaire vide qui contiendra les résultats d’évaluation (précision et taux d’erreur) pour chaque modèle (small, medium, large).\n",
    "\n",
    "Pour cela nous allons parcourir chaque paire (nom, modèle) dans le dictionnaire models. Cela permet de traiter chaque modèle individuellement.\n",
    "\n",
    "On stocke les résultats d’évaluation dans le dictionnaire results, en convertissant la précision en pourcentage (accuracy * 100) et en calculant le taux d’erreur (100 - accuracy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "for name, model in models.items():\n",
    "    # Evaluer le modèle sur les données de test (x_test, y_test). NB: Le paramètre verbose=0 désactive l'affichage.\n",
    "    scores = model.evaluate(x_test, y_test, verbose=0)\n",
    "    results[name] = {\"accuracy\": scores[1] * 100, \"error_rate\": 100 - scores[1] * 100}\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 Exemple de prédiction\n",
    "\n",
    "Nous allons visualiser un exemple concret de prédiction faite par le modèle, pour comprendre ses performances de manière plus intuitive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Affichage d'une prédiction\n",
    "def plot_sample_prediction(index):\n",
    "    plt.imshow(x_test[index].reshape(28, 28), cmap='gray')\n",
    "    pred = np.argmax(model.predict(x_test[index].reshape(1, 28, 28, 1)))\n",
    "    plt.title(f\"Prédiction: {pred} | Vérité: {y_test[index]}\")\n",
    "    plt.show()\n",
    "\n",
    "plot_sample_prediction(0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
